server:
  port: 8766
  servlet:
    context-path: /product-server


spring:
  application:
    name: product-server

  cloud:
    nacos:
      discovery:
        server-addr: 139.196.208.53:8848
        username: nacos
        password: nacos
      config:
        server-addr: 139.196.208.53:8848
        file-extension: yml
        username: nacos
        password: nacos

  redis:
    database: 0
    host: 139.196.208.53
    port: 6379
    password: 123456
    timeout: 6000ms
    lettuce:
      pool:
        max-active: 8
        max-wait: -1ms
        max-idle: 8
        min-idle: 0

  shardingsphere:
    #是否展示sql
    props:
      sql:
        show: true
    #数据源配置
    datasource:
      #数据源名称
      names: master1,master1-slave1,master1-slave2,master2,master2-slave1,master2-slave2
      master1:
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/product_master1?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&useSSL=false
        username: root
        password: Zs11195310
      master1-slave1:
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/product_master1_slave1?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&useSSL=false
        username: root
        password: Zs11195310
      master1-slave2:
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/product_master1_slave2?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&useSSL=false
        username: root
        password: Zs11195310
      master2:
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/product_master2?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&useSSL=false
        username: root
        password: Zs11195310
      master2-slave1:
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/product_master2_slave1?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&useSSL=false
        username: root
        password: Zs11195310
      master2-slave2:
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/product_master2_slave2?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&useSSL=false
        username: root
        password: Zs11195310

    masterslave:
      # 读写分离配置;用于配置从库负载均衡算法类型，可选值：ROUND_ROBIN(轮询)，RANDOM（随机）
      load-balance-algorithm-type: round_robin

    sharding:
      # 未配置分片规则的表将通过默认数据源定位
      default-data-source-name: master1
      # 公共表,操作一个库，其他库也会执行相同的CURD操作
      broadcast-tables: t_dict
      tables:
        #这个地方注意:sharding-jdbc会根据名称去找本节点，所以写sql的时候，要写此节点的名称
        t_product:
          ## 这个配置是告诉sharding有多少个表
          actual-data-nodes: master$->{1..2}.t_product_$->{0..1}
          ## 主键生成策略
          key-generator:
            #对应的数据库表的主键
            column: id
            #生成方式， 雪花模式
            type: SNOWFLAKE
          # 配置其分片策略和分片算法(分表算法)
          table-strategy:
            # 行表达式
            inline:
              # 配置sharding的计算列
              sharding-column: id
              # 配置sharding的表达式,对应的id必须和sharding-column的值对应，否则报错
              algorithm-expression: t_product_$->{id % 2}
          #分库算法
          database-strategy:
            # 行表达式
            inline:
              # 配置sharding的计算列
              sharding-column: product_type
              # 配置sharding的表达式,对应的id必须和sharding-column的值对应，否则报错
              algorithm-expression: master$->{product_type % 2 + 1}

      #读写分离
      master-slave-rules:
        # 随机起一个名称，如果配置主从，那么需要修改分表策略：：：公共表修改
        # 分表策略改成: spring.shardingsphere.sharding.tables.t_product.actual-data-nodes=master$->{1..2}.t_product_$->{0..1}
        master1:
          master-data-source-name: master1
          slave-data-source-names: master1-slave1,master1-slave2
        master2:
          master-data-source-name: master2
          slave-data-source-names: master2-slave1,master2-slave2

  rabbitmq:
    host: 139.196.208.53
    port: 5672
    username: guest
    password: guest
    virtual-host: /
    ##确认消息已发送到队列(Queue)
    publisher-returns: true
    ###确认消息已发送到交换机(Exchange)
    publisher-confirm-type: correlated
    ##exchange到queue失败,则回调return(需设置mandatory=true,否则不回回调,消息就丢了)
    template:
      mandatory: true
    listener:
      type: simple
      simple:
        #采用手动应答
        acknowledge-mode: manual
        #最小消费者数量
        concurrency: 1
        #最大消费者数量
        max-concurrency: 10
        #重试次数超过上面的设置之后是否丢弃（false不丢弃时需要写相应代码将该消息加入死信队列）
        default-requeue-rejected: false
        #是否支持重试
        retry:
          enabled: true
          #最大重试次数
          max-attempts: 3
          #重试间隔时间(单位毫秒）
          initial-interval: 5000

#rocketmq配置
cloud:
  rocketmq:
    #不能使用name-server
    name-server: 139.196.208.53:9876
    #普通消息配置
    producer:
      group: p-${spring.application.name}

    #消费者配置
    consumer:
      #消费者组名称
      c-product-server:
        subscription:
          # topic : eventCode  最好都大写
          TP_ORDER_SERVER_TOPIC: EC_ORDER_SERVER
          TP_ORDER_SERVER_TOPIC_TRANSACTION: EC_ORDER_SERVER_TRANSACTION
          TP_USER_SERVER_TOPIC: EC_USER_SERVER
          TP_USER_SERVER_TOPIC_TRANSACTION: EC_USER_SERVER_TRANSACTION


#seata分布式事务配置
seata:
  enabled: true
  application-id: ${spring.application.name}
  ##此处配置自定义的seata事务分组名称
  tx-service-group: ${spring.application.name}-tx-group
  ##开启数据库代理
  enable-auto-data-source-proxy: true
  registry:
    type: nacos
    nacos:
      application: seata-server
      server-addr: 139.196.208.53:8848
      username: nacos
      password: nacos

  config:
    type: nacos
    nacos:
      server-addr: 139.196.208.53:8848
      username: nacos
      password: nacos
      group: SEATA_GROUP
      data-id: seataServer.properties


mybatis-plus:
  mapper-locations: classpath*:mapping/*.xml
  type-aliases-package: com.cloud.common.entity
  type-enums-package: com.cloud.common.enums
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    auto-mapping-behavior: partial
  global-config:
    db-config:
      id-type: auto

###  xxl-job #############################################################
xxl:
  job:
    admin:
      #调度中心部署跟地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。
      #执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"；为空则关闭自动注册；
      addresses: http://139.196.208.53:19090/xxl-job-admin
    #### 执行器通讯TOKEN [选填]：非空时启用；
    accessToken:
    executor:
      #### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册
      appname: product-server-executor
      #### 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。
      #### 从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。
      address:
      ###执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，
      ###该IP不会绑定Host仅作为通讯实用；地址信息用于 "执行器注册" 和 "调度中心请求并触发任务"；
      ip:
      #### 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，
      #### 单机部署多个执行器时，注意要配置不同执行器端口；
      port: 0
      #### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；
      logpath: /idea_logs/springcloud_logs/xxl-job/product-server/jobhandler
      #### 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；
      logretentiondays: 30

logging:
  level:
    RocketmqClient: error
    RocketmqRemoting: warn

#hystrix的超时时间
hystrix:
  command:
    default:
      execution:
        timeout:
          enabled: true
        isolation:
          thread:
            timeoutInMilliseconds: 20000

feign:
  hystrix:
    enabled: true
  client:
    config:
      default:
        #不设置connectTimeout会导致readTimeout设置不生效
        connectTimeout: 20000
        readTimeout: 20000

